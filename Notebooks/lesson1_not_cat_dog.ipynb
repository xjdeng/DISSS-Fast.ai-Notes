{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "from path import Path as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../../../data/\"\n",
    "PATH2 = \"../../../data/Flicker8k_Dataset/\"\n",
    "sz=224\n",
    "bs = 64\n",
    "n = 1000 # Number of dogs and cats to train model on\n",
    "# imbalanced classes\n",
    "CATDOG = 0 # Dummy class variables\n",
    "NOTCATDOG = 1 # Not Cat or Not Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(filelist, suffix):\n",
    "    return [suffix + f.name for f in filelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11500\n",
      "11500\n",
      "1000\n",
      "1000\n",
      "8091\n"
     ]
    }
   ],
   "source": [
    "train_cats = get_names(p(PATH + \"dogscats/train/cats/\").files(), \"dogscats/train/cats/\")\n",
    "train_dogs = get_names(p(PATH + \"dogscats/train/dogs/\").files(), \"dogscats/train/dogs/\")\n",
    "valid_cats = get_names(p(PATH + \"dogscats/valid/cats/\").files(), \"dogscats/valid/cats/\")\n",
    "valid_dogs = get_names(p(PATH + \"dogscats/valid/dogs/\").files(), \"dogscats/valid/dogs/\")\n",
    "flickr = get_names(p(PATH2).files(), \"Flicker8k_Dataset/\")\n",
    "print(len(train_cats))\n",
    "print(len(train_dogs))\n",
    "print(len(valid_cats))\n",
    "print(len(valid_dogs))\n",
    "print(len(flickr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "catdogs = list(np.random.choice(train_cats, n, False)) + list(valid_cats)\n",
    "notcatdogs = list(np.random.choice(flickr, n + 1000, False))\n",
    "fnames = catdogs + notcatdogs\n",
    "y = np.array([CATDOG]*len(catdogs) + [NOTCATDOG]*len(notcatdogs))\n",
    "classes = list(set(y))\n",
    "v_cat_dog_idx = range(n, n + len(valid_cats))\n",
    "v_not_idx = range(len(catdogs) + n, len(fnames))\n",
    "val_idxs = list(v_cat_dog_idx) + list(v_not_idx)\n",
    "\n",
    "# fnames: file names\n",
    "# y: numpy array which contains target labels ordered by filenames.\n",
    "# classes: a list of all labels/classifications, [0, 1]\n",
    "# val_idxs: index of images to be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:23<00:00,  1.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:22<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Let's set up our model using the pretrained Resnet34 Imagenet model\n",
    "arch=resnet34\n",
    "data = ImageClassifierData.from_names_and_array(PATH, fnames, y, classes, \\\n",
    "                                                val_idxs, bs=bs, \\\n",
    "                                                tfms=tfms_from_model(arch, sz))\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f429f22384f415f8289f96e2a6f0d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                                                                              \n",
      "    0      0.126184   0.034782   0.99      \n",
      "    1      0.068991   0.023006   0.993                                                                                 \n",
      "    2      0.045593   0.019717   0.9945                                                                                \n",
      "    3      0.028688   0.022593   0.993                                                                                 \n",
      "    4      0.022849   0.018565   0.9945                                                                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.01856]), 0.9945]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a learning rate of 0.01 and train for 5 epochs\n",
    "lr = 0.01\n",
    "epochs = 5\n",
    "learn.fit(lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastAI custom",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
