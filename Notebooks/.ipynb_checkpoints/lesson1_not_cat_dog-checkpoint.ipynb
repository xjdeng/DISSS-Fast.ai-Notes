{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "from path import Path as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../../../data/\"\n",
    "PATH2 = \"../../../data/Flicker8k_Dataset/\"\n",
    "sz=224\n",
    "bs = 64\n",
    "n = 1000 # Number of dogs and cats to train model on\n",
    "# imbalanced classes\n",
    "CATDOG = 0 # Dummy class variables\n",
    "NOTCATDOG = 1 # Not Cat or Not Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(filelist, suffix):\n",
    "    return [suffix + f.name for f in filelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11500\n",
      "11500\n",
      "1000\n",
      "1000\n",
      "8091\n"
     ]
    }
   ],
   "source": [
    "train_cats = get_names(p(PATH + \"dogscats/train/cats/\").files(), \"dogscats/train/cats/\")\n",
    "train_dogs = get_names(p(PATH + \"dogscats/train/dogs/\").files(), \"dogscats/train/dogs/\")\n",
    "valid_cats = get_names(p(PATH + \"dogscats/valid/cats/\").files(), \"dogscats/valid/cats/\")\n",
    "valid_dogs = get_names(p(PATH + \"dogscats/valid/dogs/\").files(), \"dogscats/valid/dogs/\")\n",
    "flickr = get_names(p(PATH2).files(), \"Flicker8k_Dataset/\")\n",
    "print(len(train_cats))\n",
    "print(len(train_dogs))\n",
    "print(len(valid_cats))\n",
    "print(len(valid_dogs))\n",
    "print(len(flickr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Not Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(train, valid):\n",
    "    animals = list(np.random.choice(train, n, False)) + list(valid)\n",
    "    notanimals = list(np.random.choice(flickr, n + len(valid), False))\n",
    "    fname = animals + notanimals\n",
    "    y = np.array([CATDOG]*len(animals) + [NOTCATDOG]*len(notanimals))\n",
    "    classes = list(set(y))\n",
    "    v_cat_dog_idx = range(n, n + len(valid))\n",
    "    v_not_idx = range(len(animals) + n, len(fnames))\n",
    "    val_idxs = list(v_cat_dog_idx) + list(v_not_idx)\n",
    "    return (fnames, y, classes, val_idxs)\n",
    "\n",
    "# fnames: file names\n",
    "# y: numpy array which contains target labels ordered by filenames.\n",
    "# classes: a list of all labels/classifications, [0, 1]\n",
    "# val_idxs: index of images to be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames, y, classes, val_idxs = prep(train_cats, valid_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "catdogs = list(np.random.choice(train_cats, n, False)) + list(valid_cats)\n",
    "notcatdogs = list(np.random.choice(flickr, n + 1000, False))\n",
    "fnames = catdogs + notcatdogs\n",
    "y = np.array([CATDOG]*len(catdogs) + [NOTCATDOG]*len(notcatdogs))\n",
    "classes = list(set(y))\n",
    "v_cat_dog_idx = range(n, n + len(valid_cats))\n",
    "v_not_idx = range(len(catdogs) + n, len(fnames))\n",
    "val_idxs = list(v_cat_dog_idx) + list(v_not_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up our model using the pretrained Resnet34 Imagenet model\n",
    "arch=resnet34\n",
    "data = ImageClassifierData.from_names_and_array(PATH, fnames, y, classes, \\\n",
    "                                                val_idxs, bs=bs, \\\n",
    "                                                tfms=tfms_from_model(arch, sz))\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e44872d7e794127b27ac274579f82a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                                                                              \n",
      "    0      0.122568   0.028269   0.9905    \n",
      "    1      0.063907   0.02063    0.9925                                                                                \n",
      "    2      0.037626   0.019258   0.9935                                                                                \n",
      "    3      0.02648    0.018233   0.993                                                                                 \n",
      "    4      0.021621   0.017585   0.9935                                                                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.01758]), 0.9935]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a learning rate of 0.01 and train for 5 epochs\n",
    "lr = 0.01\n",
    "epochs = 5\n",
    "learn.fit(lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our prediction function\n",
    "def predict(learner, pred_files):\n",
    "    orig_precompute = learner.precompute\n",
    "    learner.precompute = False\n",
    "    trn_tfms, val_tfms = tfms_from_model(arch, sz)\n",
    "    ds = FilesIndexArrayDataset(list(pred_files), np.zeros(len(pred_files)), val_tfms, PATH)\n",
    "    dl = DataLoader(ds)\n",
    "    log_preds = learner.predict_dl(dl)\n",
    "    preds = np.exp(log_preds)\n",
    "    results = np.argmax(preds, axis=1)\n",
    "    learner.precompute = orig_precompute\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876\n"
     ]
    }
   ],
   "source": [
    "# Now try to predict on dogs\n",
    "pred_dogs = predict(learn, valid_dogs)\n",
    "print(sum(pred_dogs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastAI custom",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
