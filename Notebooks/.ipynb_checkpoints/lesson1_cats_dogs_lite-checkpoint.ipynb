{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the path.py library, included in the Anaconda distribution of Python\n",
    "from path import Path as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../../../data/dogscats/\"\n",
    "sz=224\n",
    "bs = 64\n",
    "n = 1000 # Number of dogs and cats to train model on\n",
    "n_cats = n\n",
    "n_dogs = n # We'll set these variables differently in the future for testing\n",
    "# imbalanced classes\n",
    "CAT = 0 # Dummy class variables\n",
    "DOG = 1 # Dummy class variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('../../../data/dogscats/models'),\n",
       " Path('../../../data/dogscats/sample'),\n",
       " Path('../../../data/dogscats/test1'),\n",
       " Path('../../../data/dogscats/tmp'),\n",
       " Path('../../../data/dogscats/train'),\n",
       " Path('../../../data/dogscats/valid')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(PATH).dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Path('../../../data/dogscats/train/cats'), Path('../../../data/dogscats/train/dogs')]\n",
      "[Path('../../../data/dogscats/valid/cats'), Path('../../../data/dogscats/valid/dogs')]\n"
     ]
    }
   ],
   "source": [
    "print(p(PATH + \"train/\").dirs())\n",
    "print(p(PATH + \"valid/\").dirs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create relative paths for the cat and dog files\n",
    "def get_names(filelist, suffix):\n",
    "    return [suffix + f.name for f in filelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11500\n",
      "11500\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Now we create lists of the filenames of the cats and dogs\n",
    "train_cats = get_names(p(PATH + \"train/cats/\").files(), \"train/cats/\")\n",
    "train_dogs = get_names(p(PATH + \"train/dogs/\").files(), \"train/dogs/\")\n",
    "valid_cats = get_names(p(PATH + \"valid/cats/\").files(), \"valid/cats/\")\n",
    "valid_dogs = get_names(p(PATH + \"valid/dogs/\").files(), \"valid/dogs/\")\n",
    "print(len(train_cats))\n",
    "print(len(train_dogs))\n",
    "print(len(valid_cats))\n",
    "print(len(valid_dogs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# We generate the input variables for our model later on\n",
    "p(PATH + \"tmp/\").rmtree_p()\n",
    "catfiles = list(np.random.choice(train_cats, n_cats, False)) + list(valid_cats)\n",
    "dogfiles = list(np.random.choice(train_dogs, n_dogs, False)) + list(valid_dogs)\n",
    "fnames = catfiles + dogfiles\n",
    "y = np.array([CAT]*len(catfiles) + [DOG]*len(dogfiles))\n",
    "classes = list(set(y))\n",
    "valid_cat_idxs = range(n_cats, n_cats + len(valid_cats))\n",
    "print(len(valid_cat_idxs))\n",
    "valid_dog_idxs = range(len(catfiles) + n_dogs, len(fnames))\n",
    "print(len(valid_dog_idxs))\n",
    "val_idxs = list(valid_cat_idxs) + list(valid_dog_idxs)\n",
    "                                               \n",
    "# fnames: file names\n",
    "# y: numpy array which contains target labels ordered by filenames.\n",
    "# classes: a list of all labels/classifications, [0, 1]\n",
    "# val_idxs: index of images to be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:13<00:00,  1.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:21<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Let's set up our model using the pretrained Resnet34 Imagenet model\n",
    "arch=resnet34\n",
    "data = ImageClassifierData.from_names_and_array(PATH, fnames, y, classes, \\\n",
    "                                                val_idxs, bs=bs, \\\n",
    "                                                tfms=tfms_from_model(arch, sz))\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80e6d3009dc44c38109a849a94dfdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                                                                              \n",
      "    0      0.510213   0.108337   0.969     \n",
      "    1      0.290492   0.159066   0.938                                                                                 \n",
      "    2      0.190142   0.078571   0.973                                                                                 \n",
      "    3      0.13592    0.098637   0.963                                                                                 \n",
      "    4      0.100219   0.100527   0.9615                                                                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.10053]), 0.9615]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a learning rate of 0.01 and train for 5 epochs\n",
    "lr = 0.01\n",
    "epochs = 5\n",
    "learn.fit(lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastAI custom",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
